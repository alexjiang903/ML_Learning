{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yXe7qqFO6_a0"
   },
   "source": [
    "# Shallow Neural Network in TensorFlow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jmuNn2tq6_a3"
   },
   "source": [
    "Build a shallow neural network to classify handwritten digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3kXOHzK6_a3"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/jonkrohn/DLTFpT/blob/master/notebooks/shallow_net_in_tensorflow.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3UVHR0h6_a3"
   },
   "source": [
    "#### Load dependencies here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "q3D0fOWA6_a3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ylXl_LZW6_a4"
   },
   "source": [
    "#### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ul223LE6_a5",
    "outputId": "03320d07-8a15-4292-a225-a37093872858",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data()\n",
    "print(\"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emvpQ-bf6_a5",
    "outputId": "fc2cee68-938a-4369-dd52-ca96fd6fdc56"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7OxM-LzU6_a6",
    "outputId": "8230831f-83d2-4d95-ae4d-7aee4890f3df"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjloksfO6_a6",
    "outputId": "9d4560cd-a72b-471d-981c-d36299799961"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "6ogokP4I6_a6",
    "outputId": "50951a83-cd36-4197-fadb-8fe3a6ab26f1"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "for k in range(12):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X_train[k], cmap='Greys')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OAoj2yr46_a7",
    "outputId": "425e6252-d8dd-4bb8-ef28-bc4ef08a915a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XQ0WH4-t6_a7",
    "outputId": "85c4d5cf-199c-4c48-9548-dcc629dd5ea9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "id": "yIgMMMu-6_a7",
    "outputId": "5086be9b-d6da-47ab-d2a0-c11f75950856"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = plt.imshow(X_valid[0], cmap='Greys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dG7hy3fG6_a8",
    "outputId": "a7a395b9-8ec6-4fbb-91a6-54e20ad56f8e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
       "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
       "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
       "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
       "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
       "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
       "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
       "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fAR385d56_a8",
    "outputId": "58cd7ddc-6cbc-4f8e-d4b9-49d653936bae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCYuT40d6_a8"
   },
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6Odu_77x6_a8"
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 784).astype('float32')\n",
    "X_valid = X_valid.reshape(10000, 784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "TPz3rucK6_a9"
   },
   "outputs": [],
   "source": [
    "X_train /= 255\n",
    "X_valid /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dxLl0pCg6_a9",
    "outputId": "fd7321ad-5492-4566-e4de-52420ebb9d99"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tv3n3itV6_a9"
   },
   "outputs": [],
   "source": [
    "n_classes = 10\n",
    "y_train = to_categorical(y_train, n_classes)\n",
    "y_valid = to_categorical(y_valid, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYkE_jXi6_a9",
    "outputId": "1b2be686-04ed-4aa1-bbb0-c89231c8b6d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IKupjM0z6_a9"
   },
   "source": [
    "#### Design neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "1KkhUt-m6_a-"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(64, activation='sigmoid', input_shape=(784,)))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d1__QwQt6_a-",
    "outputId": "583effe3-3e68-4cd2-c108-7b2b4872864c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                50240     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 50,890\n",
      "Trainable params: 50,890\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HjaiTp-o6_a-",
    "outputId": "6248d403-06ee-4988-8815-4c84d77cd496"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50176"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QTkzxbRA6_a-",
    "outputId": "78558e7c-b5d4-40b6-8c50-93e5c8f95d2b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50240"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(64*784)+64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jii4lIqT6_a-",
    "outputId": "d9f21530-fb53-4d40-c539-0c71cc6a8f19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "650"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(10*64)+10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2TSjHfhi6_a-"
   },
   "source": [
    "#### Configure model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aT02wHcd6_a-"
   },
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hF4I2Zou6_a-"
   },
   "source": [
    "#### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DRWqGssx6_a_",
    "outputId": "163ec0a0-bbc4-4853-8f0b-d174827944e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "469/469 [==============================] - 3s 5ms/step - loss: 0.0927 - accuracy: 0.1082 - val_loss: 0.0921 - val_accuracy: 0.1125\n",
      "Epoch 2/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0917 - accuracy: 0.1141 - val_loss: 0.0914 - val_accuracy: 0.1145\n",
      "Epoch 3/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0911 - accuracy: 0.1167 - val_loss: 0.0909 - val_accuracy: 0.1212\n",
      "Epoch 4/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0907 - accuracy: 0.1248 - val_loss: 0.0905 - val_accuracy: 0.1327\n",
      "Epoch 5/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0903 - accuracy: 0.1428 - val_loss: 0.0901 - val_accuracy: 0.1518\n",
      "Epoch 6/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0899 - accuracy: 0.1691 - val_loss: 0.0898 - val_accuracy: 0.1811\n",
      "Epoch 7/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0896 - accuracy: 0.2013 - val_loss: 0.0894 - val_accuracy: 0.2177\n",
      "Epoch 8/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0893 - accuracy: 0.2331 - val_loss: 0.0891 - val_accuracy: 0.2478\n",
      "Epoch 9/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0890 - accuracy: 0.2651 - val_loss: 0.0888 - val_accuracy: 0.2807\n",
      "Epoch 10/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0887 - accuracy: 0.2981 - val_loss: 0.0885 - val_accuracy: 0.3105\n",
      "Epoch 11/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0884 - accuracy: 0.3254 - val_loss: 0.0882 - val_accuracy: 0.3364\n",
      "Epoch 12/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0881 - accuracy: 0.3506 - val_loss: 0.0879 - val_accuracy: 0.3548\n",
      "Epoch 13/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0877 - accuracy: 0.3643 - val_loss: 0.0876 - val_accuracy: 0.3670\n",
      "Epoch 14/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0874 - accuracy: 0.3737 - val_loss: 0.0872 - val_accuracy: 0.3745\n",
      "Epoch 15/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0871 - accuracy: 0.3793 - val_loss: 0.0869 - val_accuracy: 0.3806\n",
      "Epoch 16/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.3855 - val_loss: 0.0866 - val_accuracy: 0.3843\n",
      "Epoch 17/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0865 - accuracy: 0.3880 - val_loss: 0.0863 - val_accuracy: 0.3878\n",
      "Epoch 18/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0861 - accuracy: 0.3911 - val_loss: 0.0859 - val_accuracy: 0.3920\n",
      "Epoch 19/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0858 - accuracy: 0.3923 - val_loss: 0.0856 - val_accuracy: 0.3920\n",
      "Epoch 20/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0855 - accuracy: 0.3936 - val_loss: 0.0853 - val_accuracy: 0.3936\n",
      "Epoch 21/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0851 - accuracy: 0.3945 - val_loss: 0.0849 - val_accuracy: 0.3949\n",
      "Epoch 22/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0848 - accuracy: 0.3956 - val_loss: 0.0846 - val_accuracy: 0.3973\n",
      "Epoch 23/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0844 - accuracy: 0.3971 - val_loss: 0.0842 - val_accuracy: 0.3983\n",
      "Epoch 24/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0841 - accuracy: 0.3979 - val_loss: 0.0839 - val_accuracy: 0.3994\n",
      "Epoch 25/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0837 - accuracy: 0.4002 - val_loss: 0.0835 - val_accuracy: 0.4009\n",
      "Epoch 26/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0834 - accuracy: 0.4003 - val_loss: 0.0831 - val_accuracy: 0.4006\n",
      "Epoch 27/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0830 - accuracy: 0.4018 - val_loss: 0.0827 - val_accuracy: 0.4006\n",
      "Epoch 28/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0826 - accuracy: 0.4029 - val_loss: 0.0823 - val_accuracy: 0.4026\n",
      "Epoch 29/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0822 - accuracy: 0.4042 - val_loss: 0.0820 - val_accuracy: 0.4051\n",
      "Epoch 30/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0818 - accuracy: 0.4064 - val_loss: 0.0815 - val_accuracy: 0.4058\n",
      "Epoch 31/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0814 - accuracy: 0.4084 - val_loss: 0.0811 - val_accuracy: 0.4077\n",
      "Epoch 32/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0810 - accuracy: 0.4114 - val_loss: 0.0807 - val_accuracy: 0.4106\n",
      "Epoch 33/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0806 - accuracy: 0.4142 - val_loss: 0.0803 - val_accuracy: 0.4125\n",
      "Epoch 34/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0802 - accuracy: 0.4163 - val_loss: 0.0799 - val_accuracy: 0.4163\n",
      "Epoch 35/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0798 - accuracy: 0.4198 - val_loss: 0.0795 - val_accuracy: 0.4194\n",
      "Epoch 36/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0793 - accuracy: 0.4231 - val_loss: 0.0790 - val_accuracy: 0.4221\n",
      "Epoch 37/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0789 - accuracy: 0.4258 - val_loss: 0.0786 - val_accuracy: 0.4256\n",
      "Epoch 38/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.4301 - val_loss: 0.0781 - val_accuracy: 0.4290\n",
      "Epoch 39/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0780 - accuracy: 0.4336 - val_loss: 0.0777 - val_accuracy: 0.4321\n",
      "Epoch 40/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0776 - accuracy: 0.4373 - val_loss: 0.0772 - val_accuracy: 0.4362\n",
      "Epoch 41/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0771 - accuracy: 0.4407 - val_loss: 0.0767 - val_accuracy: 0.4407\n",
      "Epoch 42/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0766 - accuracy: 0.4464 - val_loss: 0.0763 - val_accuracy: 0.4451\n",
      "Epoch 43/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0762 - accuracy: 0.4493 - val_loss: 0.0758 - val_accuracy: 0.4488\n",
      "Epoch 44/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0757 - accuracy: 0.4540 - val_loss: 0.0753 - val_accuracy: 0.4529\n",
      "Epoch 45/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0752 - accuracy: 0.4582 - val_loss: 0.0749 - val_accuracy: 0.4571\n",
      "Epoch 46/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0748 - accuracy: 0.4615 - val_loss: 0.0744 - val_accuracy: 0.4615\n",
      "Epoch 47/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0743 - accuracy: 0.4658 - val_loss: 0.0739 - val_accuracy: 0.4656\n",
      "Epoch 48/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0738 - accuracy: 0.4708 - val_loss: 0.0734 - val_accuracy: 0.4692\n",
      "Epoch 49/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0733 - accuracy: 0.4748 - val_loss: 0.0729 - val_accuracy: 0.4741\n",
      "Epoch 50/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0729 - accuracy: 0.4791 - val_loss: 0.0724 - val_accuracy: 0.4779\n",
      "Epoch 51/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0724 - accuracy: 0.4832 - val_loss: 0.0720 - val_accuracy: 0.4822\n",
      "Epoch 52/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0719 - accuracy: 0.4874 - val_loss: 0.0715 - val_accuracy: 0.4879\n",
      "Epoch 53/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0714 - accuracy: 0.4918 - val_loss: 0.0710 - val_accuracy: 0.4918\n",
      "Epoch 54/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0709 - accuracy: 0.4963 - val_loss: 0.0705 - val_accuracy: 0.4962\n",
      "Epoch 55/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0705 - accuracy: 0.5005 - val_loss: 0.0700 - val_accuracy: 0.5003\n",
      "Epoch 56/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0700 - accuracy: 0.5049 - val_loss: 0.0695 - val_accuracy: 0.5042\n",
      "Epoch 57/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0695 - accuracy: 0.5083 - val_loss: 0.0690 - val_accuracy: 0.5093\n",
      "Epoch 58/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0690 - accuracy: 0.5132 - val_loss: 0.0685 - val_accuracy: 0.5138\n",
      "Epoch 59/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0685 - accuracy: 0.5174 - val_loss: 0.0681 - val_accuracy: 0.5207\n",
      "Epoch 60/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0681 - accuracy: 0.5221 - val_loss: 0.0676 - val_accuracy: 0.5250\n",
      "Epoch 61/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0676 - accuracy: 0.5274 - val_loss: 0.0671 - val_accuracy: 0.5316\n",
      "Epoch 62/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0671 - accuracy: 0.5325 - val_loss: 0.0666 - val_accuracy: 0.5363\n",
      "Epoch 63/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0666 - accuracy: 0.5373 - val_loss: 0.0661 - val_accuracy: 0.5412\n",
      "Epoch 64/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0662 - accuracy: 0.5430 - val_loss: 0.0657 - val_accuracy: 0.5475\n",
      "Epoch 65/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0657 - accuracy: 0.5479 - val_loss: 0.0652 - val_accuracy: 0.5526\n",
      "Epoch 66/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0653 - accuracy: 0.5527 - val_loss: 0.0647 - val_accuracy: 0.5597\n",
      "Epoch 67/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.5576 - val_loss: 0.0643 - val_accuracy: 0.5660\n",
      "Epoch 68/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0643 - accuracy: 0.5627 - val_loss: 0.0638 - val_accuracy: 0.5729\n",
      "Epoch 69/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0639 - accuracy: 0.5685 - val_loss: 0.0633 - val_accuracy: 0.5778\n",
      "Epoch 70/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0634 - accuracy: 0.5741 - val_loss: 0.0629 - val_accuracy: 0.5832\n",
      "Epoch 71/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0630 - accuracy: 0.5794 - val_loss: 0.0624 - val_accuracy: 0.5903\n",
      "Epoch 72/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0625 - accuracy: 0.5856 - val_loss: 0.0620 - val_accuracy: 0.5952\n",
      "Epoch 73/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.5909 - val_loss: 0.0615 - val_accuracy: 0.6007\n",
      "Epoch 74/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0616 - accuracy: 0.5969 - val_loss: 0.0611 - val_accuracy: 0.6059\n",
      "Epoch 75/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0612 - accuracy: 0.6025 - val_loss: 0.0606 - val_accuracy: 0.6112\n",
      "Epoch 76/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0608 - accuracy: 0.6074 - val_loss: 0.0602 - val_accuracy: 0.6158\n",
      "Epoch 77/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0603 - accuracy: 0.6130 - val_loss: 0.0597 - val_accuracy: 0.6208\n",
      "Epoch 78/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0599 - accuracy: 0.6191 - val_loss: 0.0593 - val_accuracy: 0.6262\n",
      "Epoch 79/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0595 - accuracy: 0.6238 - val_loss: 0.0589 - val_accuracy: 0.6314\n",
      "Epoch 80/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0591 - accuracy: 0.6288 - val_loss: 0.0584 - val_accuracy: 0.6366\n",
      "Epoch 81/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0586 - accuracy: 0.6341 - val_loss: 0.0580 - val_accuracy: 0.6410\n",
      "Epoch 82/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0582 - accuracy: 0.6391 - val_loss: 0.0576 - val_accuracy: 0.6463\n",
      "Epoch 83/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0578 - accuracy: 0.6440 - val_loss: 0.0572 - val_accuracy: 0.6522\n",
      "Epoch 84/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0574 - accuracy: 0.6483 - val_loss: 0.0568 - val_accuracy: 0.6567\n",
      "Epoch 85/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0570 - accuracy: 0.6525 - val_loss: 0.0563 - val_accuracy: 0.6608\n",
      "Epoch 86/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0566 - accuracy: 0.6572 - val_loss: 0.0559 - val_accuracy: 0.6647\n",
      "Epoch 87/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0562 - accuracy: 0.6610 - val_loss: 0.0555 - val_accuracy: 0.6702\n",
      "Epoch 88/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0558 - accuracy: 0.6653 - val_loss: 0.0551 - val_accuracy: 0.6736\n",
      "Epoch 89/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0554 - accuracy: 0.6693 - val_loss: 0.0547 - val_accuracy: 0.6773\n",
      "Epoch 90/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0550 - accuracy: 0.6732 - val_loss: 0.0543 - val_accuracy: 0.6810\n",
      "Epoch 91/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0546 - accuracy: 0.6763 - val_loss: 0.0539 - val_accuracy: 0.6851\n",
      "Epoch 92/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0542 - accuracy: 0.6801 - val_loss: 0.0536 - val_accuracy: 0.6879\n",
      "Epoch 93/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0539 - accuracy: 0.6832 - val_loss: 0.0532 - val_accuracy: 0.6919\n",
      "Epoch 94/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0535 - accuracy: 0.6868 - val_loss: 0.0528 - val_accuracy: 0.6946\n",
      "Epoch 95/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0531 - accuracy: 0.6901 - val_loss: 0.0524 - val_accuracy: 0.6975\n",
      "Epoch 96/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.6930 - val_loss: 0.0520 - val_accuracy: 0.7007\n",
      "Epoch 97/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0524 - accuracy: 0.6960 - val_loss: 0.0517 - val_accuracy: 0.7038\n",
      "Epoch 98/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0520 - accuracy: 0.6989 - val_loss: 0.0513 - val_accuracy: 0.7067\n",
      "Epoch 99/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0517 - accuracy: 0.7013 - val_loss: 0.0509 - val_accuracy: 0.7104\n",
      "Epoch 100/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0513 - accuracy: 0.7041 - val_loss: 0.0506 - val_accuracy: 0.7122\n",
      "Epoch 101/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0509 - accuracy: 0.7066 - val_loss: 0.0502 - val_accuracy: 0.7145\n",
      "Epoch 102/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0506 - accuracy: 0.7096 - val_loss: 0.0499 - val_accuracy: 0.7175\n",
      "Epoch 103/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0503 - accuracy: 0.7118 - val_loss: 0.0495 - val_accuracy: 0.7199\n",
      "Epoch 104/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0499 - accuracy: 0.7148 - val_loss: 0.0492 - val_accuracy: 0.7234\n",
      "Epoch 105/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0496 - accuracy: 0.7166 - val_loss: 0.0488 - val_accuracy: 0.7259\n",
      "Epoch 106/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0492 - accuracy: 0.7192 - val_loss: 0.0485 - val_accuracy: 0.7284\n",
      "Epoch 107/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0489 - accuracy: 0.7211 - val_loss: 0.0482 - val_accuracy: 0.7298\n",
      "Epoch 108/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0486 - accuracy: 0.7232 - val_loss: 0.0478 - val_accuracy: 0.7314\n",
      "Epoch 109/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0483 - accuracy: 0.7249 - val_loss: 0.0475 - val_accuracy: 0.7337\n",
      "Epoch 110/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0479 - accuracy: 0.7270 - val_loss: 0.0472 - val_accuracy: 0.7353\n",
      "Epoch 111/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0476 - accuracy: 0.7291 - val_loss: 0.0469 - val_accuracy: 0.7384\n",
      "Epoch 112/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0473 - accuracy: 0.7311 - val_loss: 0.0466 - val_accuracy: 0.7406\n",
      "Epoch 113/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0470 - accuracy: 0.7331 - val_loss: 0.0462 - val_accuracy: 0.7426\n",
      "Epoch 114/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0467 - accuracy: 0.7348 - val_loss: 0.0459 - val_accuracy: 0.7443\n",
      "Epoch 115/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0464 - accuracy: 0.7366 - val_loss: 0.0456 - val_accuracy: 0.7467\n",
      "Epoch 116/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0461 - accuracy: 0.7380 - val_loss: 0.0453 - val_accuracy: 0.7488\n",
      "Epoch 117/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0458 - accuracy: 0.7398 - val_loss: 0.0450 - val_accuracy: 0.7503\n",
      "Epoch 118/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0455 - accuracy: 0.7413 - val_loss: 0.0447 - val_accuracy: 0.7521\n",
      "Epoch 119/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0452 - accuracy: 0.7431 - val_loss: 0.0444 - val_accuracy: 0.7533\n",
      "Epoch 120/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0449 - accuracy: 0.7450 - val_loss: 0.0442 - val_accuracy: 0.7539\n",
      "Epoch 121/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0447 - accuracy: 0.7467 - val_loss: 0.0439 - val_accuracy: 0.7566\n",
      "Epoch 122/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.7481 - val_loss: 0.0436 - val_accuracy: 0.7581\n",
      "Epoch 123/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0441 - accuracy: 0.7495 - val_loss: 0.0433 - val_accuracy: 0.7590\n",
      "Epoch 124/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.7509 - val_loss: 0.0430 - val_accuracy: 0.7606\n",
      "Epoch 125/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0436 - accuracy: 0.7526 - val_loss: 0.0428 - val_accuracy: 0.7620\n",
      "Epoch 126/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0433 - accuracy: 0.7542 - val_loss: 0.0425 - val_accuracy: 0.7637\n",
      "Epoch 127/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0430 - accuracy: 0.7558 - val_loss: 0.0422 - val_accuracy: 0.7652\n",
      "Epoch 128/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0428 - accuracy: 0.7573 - val_loss: 0.0419 - val_accuracy: 0.7667\n",
      "Epoch 129/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0425 - accuracy: 0.7589 - val_loss: 0.0417 - val_accuracy: 0.7679\n",
      "Epoch 130/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.7604 - val_loss: 0.0414 - val_accuracy: 0.7692\n",
      "Epoch 131/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0420 - accuracy: 0.7621 - val_loss: 0.0412 - val_accuracy: 0.7714\n",
      "Epoch 132/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0417 - accuracy: 0.7639 - val_loss: 0.0409 - val_accuracy: 0.7730\n",
      "Epoch 133/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0415 - accuracy: 0.7654 - val_loss: 0.0407 - val_accuracy: 0.7747\n",
      "Epoch 134/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0412 - accuracy: 0.7670 - val_loss: 0.0404 - val_accuracy: 0.7771\n",
      "Epoch 135/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0410 - accuracy: 0.7686 - val_loss: 0.0402 - val_accuracy: 0.7791\n",
      "Epoch 136/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0408 - accuracy: 0.7703 - val_loss: 0.0399 - val_accuracy: 0.7812\n",
      "Epoch 137/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0405 - accuracy: 0.7720 - val_loss: 0.0397 - val_accuracy: 0.7830\n",
      "Epoch 138/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0403 - accuracy: 0.7741 - val_loss: 0.0394 - val_accuracy: 0.7852\n",
      "Epoch 139/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0400 - accuracy: 0.7761 - val_loss: 0.0392 - val_accuracy: 0.7865\n",
      "Epoch 140/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0398 - accuracy: 0.7780 - val_loss: 0.0390 - val_accuracy: 0.7882\n",
      "Epoch 141/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0396 - accuracy: 0.7803 - val_loss: 0.0387 - val_accuracy: 0.7897\n",
      "Epoch 142/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0394 - accuracy: 0.7822 - val_loss: 0.0385 - val_accuracy: 0.7918\n",
      "Epoch 143/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0391 - accuracy: 0.7839 - val_loss: 0.0383 - val_accuracy: 0.7936\n",
      "Epoch 144/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0389 - accuracy: 0.7858 - val_loss: 0.0381 - val_accuracy: 0.7959\n",
      "Epoch 145/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0387 - accuracy: 0.7878 - val_loss: 0.0378 - val_accuracy: 0.7980\n",
      "Epoch 146/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0385 - accuracy: 0.7894 - val_loss: 0.0376 - val_accuracy: 0.8006\n",
      "Epoch 147/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0383 - accuracy: 0.7911 - val_loss: 0.0374 - val_accuracy: 0.8025\n",
      "Epoch 148/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0380 - accuracy: 0.7931 - val_loss: 0.0372 - val_accuracy: 0.8044\n",
      "Epoch 149/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0378 - accuracy: 0.7945 - val_loss: 0.0370 - val_accuracy: 0.8066\n",
      "Epoch 150/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0376 - accuracy: 0.7967 - val_loss: 0.0368 - val_accuracy: 0.8081\n",
      "Epoch 151/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0374 - accuracy: 0.7985 - val_loss: 0.0365 - val_accuracy: 0.8102\n",
      "Epoch 152/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0372 - accuracy: 0.8001 - val_loss: 0.0363 - val_accuracy: 0.8113\n",
      "Epoch 153/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.8023 - val_loss: 0.0361 - val_accuracy: 0.8124\n",
      "Epoch 154/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0368 - accuracy: 0.8044 - val_loss: 0.0359 - val_accuracy: 0.8142\n",
      "Epoch 155/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0366 - accuracy: 0.8058 - val_loss: 0.0357 - val_accuracy: 0.8160\n",
      "Epoch 156/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0364 - accuracy: 0.8072 - val_loss: 0.0355 - val_accuracy: 0.8177\n",
      "Epoch 157/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0362 - accuracy: 0.8084 - val_loss: 0.0353 - val_accuracy: 0.8194\n",
      "Epoch 158/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0360 - accuracy: 0.8101 - val_loss: 0.0351 - val_accuracy: 0.8213\n",
      "Epoch 159/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0358 - accuracy: 0.8118 - val_loss: 0.0349 - val_accuracy: 0.8227\n",
      "Epoch 160/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0356 - accuracy: 0.8135 - val_loss: 0.0348 - val_accuracy: 0.8239\n",
      "Epoch 161/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0355 - accuracy: 0.8152 - val_loss: 0.0346 - val_accuracy: 0.8252\n",
      "Epoch 162/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.8167 - val_loss: 0.0344 - val_accuracy: 0.8270\n",
      "Epoch 163/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0351 - accuracy: 0.8180 - val_loss: 0.0342 - val_accuracy: 0.8284\n",
      "Epoch 164/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0349 - accuracy: 0.8191 - val_loss: 0.0340 - val_accuracy: 0.8291\n",
      "Epoch 165/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0347 - accuracy: 0.8208 - val_loss: 0.0338 - val_accuracy: 0.8301\n",
      "Epoch 166/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0346 - accuracy: 0.8222 - val_loss: 0.0336 - val_accuracy: 0.8311\n",
      "Epoch 167/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0344 - accuracy: 0.8235 - val_loss: 0.0335 - val_accuracy: 0.8325\n",
      "Epoch 168/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0342 - accuracy: 0.8245 - val_loss: 0.0333 - val_accuracy: 0.8332\n",
      "Epoch 169/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0340 - accuracy: 0.8255 - val_loss: 0.0331 - val_accuracy: 0.8342\n",
      "Epoch 170/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0339 - accuracy: 0.8269 - val_loss: 0.0330 - val_accuracy: 0.8350\n",
      "Epoch 171/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0337 - accuracy: 0.8277 - val_loss: 0.0328 - val_accuracy: 0.8367\n",
      "Epoch 172/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0335 - accuracy: 0.8288 - val_loss: 0.0326 - val_accuracy: 0.8375\n",
      "Epoch 173/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0334 - accuracy: 0.8299 - val_loss: 0.0324 - val_accuracy: 0.8382\n",
      "Epoch 174/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0332 - accuracy: 0.8307 - val_loss: 0.0323 - val_accuracy: 0.8395\n",
      "Epoch 175/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0330 - accuracy: 0.8314 - val_loss: 0.0321 - val_accuracy: 0.8406\n",
      "Epoch 176/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0329 - accuracy: 0.8327 - val_loss: 0.0320 - val_accuracy: 0.8418\n",
      "Epoch 177/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0327 - accuracy: 0.8338 - val_loss: 0.0318 - val_accuracy: 0.8426\n",
      "Epoch 178/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0326 - accuracy: 0.8345 - val_loss: 0.0316 - val_accuracy: 0.8434\n",
      "Epoch 179/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0324 - accuracy: 0.8356 - val_loss: 0.0315 - val_accuracy: 0.8441\n",
      "Epoch 180/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.8368 - val_loss: 0.0313 - val_accuracy: 0.8453\n",
      "Epoch 181/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0321 - accuracy: 0.8375 - val_loss: 0.0312 - val_accuracy: 0.8466\n",
      "Epoch 182/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0320 - accuracy: 0.8383 - val_loss: 0.0310 - val_accuracy: 0.8478\n",
      "Epoch 183/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0318 - accuracy: 0.8390 - val_loss: 0.0309 - val_accuracy: 0.8485\n",
      "Epoch 184/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0317 - accuracy: 0.8397 - val_loss: 0.0307 - val_accuracy: 0.8492\n",
      "Epoch 185/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0315 - accuracy: 0.8402 - val_loss: 0.0306 - val_accuracy: 0.8495\n",
      "Epoch 186/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0314 - accuracy: 0.8410 - val_loss: 0.0304 - val_accuracy: 0.8502\n",
      "Epoch 187/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0312 - accuracy: 0.8419 - val_loss: 0.0303 - val_accuracy: 0.8513\n",
      "Epoch 188/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0311 - accuracy: 0.8427 - val_loss: 0.0302 - val_accuracy: 0.8515\n",
      "Epoch 189/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0310 - accuracy: 0.8432 - val_loss: 0.0300 - val_accuracy: 0.8516\n",
      "Epoch 190/200\n",
      "469/469 [==============================] - 2s 5ms/step - loss: 0.0308 - accuracy: 0.8440 - val_loss: 0.0299 - val_accuracy: 0.8521\n",
      "Epoch 191/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0307 - accuracy: 0.8447 - val_loss: 0.0297 - val_accuracy: 0.8524\n",
      "Epoch 192/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0305 - accuracy: 0.8456 - val_loss: 0.0296 - val_accuracy: 0.8535\n",
      "Epoch 193/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0304 - accuracy: 0.8462 - val_loss: 0.0295 - val_accuracy: 0.8544\n",
      "Epoch 194/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0303 - accuracy: 0.8468 - val_loss: 0.0293 - val_accuracy: 0.8553\n",
      "Epoch 195/200\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0302 - accuracy: 0.8475 - val_loss: 0.0292 - val_accuracy: 0.8567\n",
      "Epoch 196/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0300 - accuracy: 0.8480 - val_loss: 0.0291 - val_accuracy: 0.8569\n",
      "Epoch 197/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0299 - accuracy: 0.8487 - val_loss: 0.0289 - val_accuracy: 0.8578\n",
      "Epoch 198/200\n",
      "469/469 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.8491 - val_loss: 0.0288 - val_accuracy: 0.8583\n",
      "Epoch 199/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0297 - accuracy: 0.8497 - val_loss: 0.0287 - val_accuracy: 0.8586\n",
      "Epoch 200/200\n",
      "469/469 [==============================] - 2s 3ms/step - loss: 0.0295 - accuracy: 0.8505 - val_loss: 0.0286 - val_accuracy: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6aa77e1040>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFFJFRyv6_a_"
   },
   "source": [
    "#### Evaluating model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mi8oSUj06_a_",
    "outputId": "4d2dd5bf-8fbf-43b9-9445-884d2b0b22bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 0.0286 - accuracy: 0.8586\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.028574416413903236, 0.8586000204086304]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m5kN0zO56_a_"
   },
   "source": [
    "#### Performing inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-i_2NQrm6_a_"
   },
   "outputs": [],
   "source": [
    "valid_0 = X_valid[0].reshape(1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1uDQLTJv6_a_",
    "outputId": "f924b84e-1c66-4420-e441-cd7e952fef42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 90ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.0981658e-03, 1.0899013e-03, 3.9723762e-03, 7.7837198e-03,\n",
       "        6.3838577e-03, 8.0801407e-03, 8.3499949e-04, 9.2163819e-01,\n",
       "        4.1949092e-03, 4.1923724e-02]], dtype=float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(valid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "b2cxqZcL8k7C"
   },
   "outputs": [],
   "source": [
    "# model.predict_classes(valid_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UV84XMx6_a_",
    "outputId": "c5b7e7b4-81a8-465e-f8a9-e62e3fe02f60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The predict_classes() method no longer exists in recent TensorFlow releases. \n",
    "# Instead you could use:\n",
    "import numpy as np\n",
    "np.argmax(model.predict(valid_0), axis=-1)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "name": "shallow_net_in_tensorflow.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
