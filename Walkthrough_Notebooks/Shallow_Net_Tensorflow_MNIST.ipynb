{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bba8daa",
   "metadata": {},
   "source": [
    "# Walkthrough of Tensorsflow Shallow Net (Lesson 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd9271",
   "metadata": {},
   "source": [
    "- We are building a digit classifier using a shallow neural network of 3 layers\n",
    "    - ### Layer 1: input layer (28x28 pixels, or 784 inputs)\n",
    "        - Each pixel has an 8 digit value representing its colour (0 = white, 255 = black)\n",
    "   \n",
    "   - ### Layer 2: 64 sigmoid neurons (hidden layer)\n",
    "   \n",
    "   - ### Layer 3: 10 softmax neurons (output layer)\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66166e9",
   "metadata": {},
   "source": [
    "### Load the required dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6620919",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.datasets import mnist #Keras module to build tensorflow model easily\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input #added input layer import for specifying input sizes\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot as plt #for visualization purposes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4de9d",
   "metadata": {},
   "source": [
    "### Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd4ceb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "successfully loaded MNIST data\n"
     ]
    }
   ],
   "source": [
    "#x is the inputs, y is the outputs in the training/validation datasets\n",
    "(X_train, y_train), (X_valid, y_valid) = mnist.load_data() \n",
    "print(\"successfully loaded MNIST data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59c3e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape #60,000 input images in MNIST data set, each are 28x28 pixels in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319a0f04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape  #Corresponding label for each input image (60,000 labels for 60,000 digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0937d5a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8979a92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the first 12 training images to see what they look like (corresponds to labels)\n",
    "plt.figure(figsize=(5,5))\n",
    "for k in range(12):\n",
    "    plt.subplot(3, 4, k+1)\n",
    "    plt.imshow(X_train[k], cmap='Greys')\n",
    "    plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba5394d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Look at the shape of the validation data\n",
    "X_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5f87aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72ce9807",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x164001520>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAYwklEQVR4nO3df2xV1QEH8FNUKiotKwilUhD8PX+w6RTx13QQ0C1GlCz++gMWA5GBGXZO08VfuCXdNHFMw/AfR2fmr5mIRP9gURDQDTTgCNFtBBAHRoo/ElpAQQJ3Ode0o4K6V1pO+97nk9y8vvfu6T1cTu/3nXvPPa8sy7IsAMBh1utwbxAAIgEEQBICCIAkBBAASQggAJIQQAAkIYAASEIAAZDEkaGb2bdvX/jggw9C3759Q1lZWerqAFCgOL/B9u3bQ01NTejVq1fPCaAYPrW1tamrAcAh2rx5cxgyZEjPCaDY82mteEVFRerqAFCglpaWvCPRejw/7AE0Z86c8NBDD4WmpqYwcuTI8Oijj4YLLrjgG8u1nnaL4SOAAHqub7qM0iWDEJ599tlQV1cX7rvvvvDWW2/lATR+/Pjw4YcfdsXmAOiBuiSAHn744TBlypTwk5/8JHz7298Ojz32WDjmmGPCH//4x67YHAA9UKcH0Oeffx5WrVoVxo4d+7+N9OqVP1++fPkB6+/evTs/X7j/AkDx6/QA+vjjj8PevXvDoEGD2r0en8frQV/W0NAQKisr2xYj4ABKQ/IbUevr60Nzc3PbEke/AVD8On0U3IABA8IRRxwRtm7d2u71+Ly6uvqA9cvLy/MFgNLS6T2g3r17h/POOy8sWrSo3ewG8fno0aM7e3MA9FBdch9QHII9adKk8L3vfS+/92f27Nlh586d+ag4AOiyALr++uvDRx99FO6999584MF3vvOdsHDhwgMGJgBQusqyOGtcNxKHYcfRcHFAgpkQAHqe//c4nnwUHAClSQABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAiiOA7r///lBWVtZuOf300zt7MwD0cEd2xS8988wzwyuvvPK/jRzZJZsBoAfrkmSIgVNdXd0VvxqAItEl14DWrVsXampqwogRI8LNN98cNm3a9JXr7t69O7S0tLRbACh+nR5Ao0aNCo2NjWHhwoVh7ty5YePGjeHSSy8N27dvP+j6DQ0NobKysm2pra3t7CoB0A2VZVmWdeUGtm3bFoYNGxYefvjhcMsttxy0BxSXVrEHFEOoubk5VFRUdGXVAOgC8TgeOxTfdBzv8tEB/fr1C6eeempYv379Qd8vLy/PFwBKS5ffB7Rjx46wYcOGMHjw4K7eFAClHEB33HFHWLp0aXjvvffC3//+93DttdeGI444Itx4442dvSkAerBOPwX3/vvv52HzySefhOOPPz5ccsklYcWKFfnPANBlAfTMM8909q8EoAiZCw6AJAQQAEkIIACSEEAAJCGAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJNHlX0jH4RVnHi/U73//+w5t64QTTii4TJ8+fQouM2nSpILLVFVVFVzmUMoBhdMDAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkijLsiwL3UhLS0uorKwMzc3NoaKiInV1epzTTjut4DLr1q0LxSa2oY648MILO70udK4TTzyx4DL19fUd2tbQoUM7VK7Utfyfx3E9IACSEEAAJCGAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAGQxJFpNktXeeGFFwous3r16g5t68wzzyy4zDvvvFNwmTfeeKPgMgsWLAgd8de//rXgMsOHDy+4zMaNG0N3duSRhR8aBg8eXHCZzZs3h+46gWl01113dXpd+B89IACSEEAAJCGAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAGQRFmWZVnoRlpaWkJlZWVobm4OFRUVqatDD7Vr164OlXvvvfcOy2Sk7777bujOevfufVgmI+3Ivvvoo48KLjN//vzQEddcc02HypW6lv/zOK4HBEASAgiAnhFAy5YtC1dffXWoqakJZWVlB3z/TDyjd++99+bd8T59+oSxY8eGdevWdWadASjFANq5c2cYOXJkmDNnzkHff/DBB8MjjzwSHnvssfyLxI499tgwfvz4Dp+TB6A4Ffy1h1dddVW+HEzs/cyePTvcfffdbRfvnnjiiTBo0KC8p3TDDTcceo0BKAqdeg0ofs1wU1NTftqtVRwJMWrUqLB8+fKDltm9e3c+YmL/BYDi16kBFMMnij2e/cXnre99WUNDQx5SrUttbW1nVgmAbir5KLj6+vp8rHjrsnnz5tRVAqCnBVB1dXX+uHXr1navx+et731ZeXl5fqPS/gsAxa9TAyje1RyDZtGiRW2vxWs6cTTc6NGjO3NTAJTaKLgdO3aE9evXtxt4sHr16lBVVRWGDh0aZs6cGX7961+HU045JQ+ke+65J79naMKECZ1ddwBKKYBWrlwZrrjiirbndXV1+eOkSZNCY2NjuPPOO/N7haZOnRq2bdsWLrnkkrBw4cJw9NFHd27NAejRTEYKdIp4qr1QF110UcFlLrjggoLLLF68OHREnM2FwpmMFIBuTQABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgJ7xdQxA8YtfqVKoa6+9tuAy+/btK7jM7NmzCy5jVuvuSQ8IgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACRhMlLgAI2NjQWXaWpqKrhM//79Cy4zbNiwgsvQPekBAZCEAAIgCQEEQBICCIAkBBAASQggAJIQQAAkIYAASEIAAZCEAAIgCQEEQBICCIAkTEYKRWzDhg0dKldXVxcOh+XLlxdcprq6ukvqwuGnBwRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkjAZKRSxF198sUPl9uzZU3CZH//4xwWXGTFiRMFlKB56QAAkIYAA6BkBtGzZsnD11VeHmpqaUFZWFl544YV270+ePDl/ff/lyiuv7Mw6A1CKAbRz584wcuTIMGfOnK9cJwbOli1b2pann376UOsJQKkPQrjqqqvy5euUl5f71kIADv81oCVLloSBAweG0047LUybNi188sknX7nu7t27Q0tLS7sFgOLX6QEUT7898cQTYdGiReG3v/1tWLp0ad5j2rt370HXb2hoCJWVlW1LbW1tZ1cJgFK4D+iGG25o+/nss88O55xzTjjppJPyXtGYMWMOWL++vj7U1dW1PY89ICEEUPy6fBh2vNFswIABYf369V95vaiioqLdAkDx6/IAev/99/NrQIMHD+7qTQFQzKfgduzY0a43s3HjxrB69epQVVWVL7NmzQoTJ07MR8Ft2LAh3HnnneHkk08O48eP7+y6A1BKAbRy5cpwxRVXtD1vvX4zadKkMHfu3LBmzZrwpz/9KWzbti2/WXXcuHHhV7/6VX6qDQBalWVZloVuJA5CiKPhmpubXQ+CQ5wgdOzYsR3a1ptvvllwmXfeeafgMiYjLU7/73HcXHAAJCGAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAGQhAACIAkBBEBxfCU30DUef/zxgsu89tprHdrWTTfdVHAZM1tTKD0gAJIQQAAkIYAASEIAAZCEAAIgCQEEQBICCIAkBBAASQggAJIQQAAkIYAASEIAAZCEyUghgdWrVxdc5rbbbiu4TL9+/UJHPPDAAx0qB4XQAwIgCQEEQBICCIAkBBAASQggAJIQQAAkIYAASEIAAZCEAAIgCQEEQBICCIAkBBAASZiMFA7RZ599VnCZG2+8seAye/fuLbjMzTffHDpixIgRHSoHhdADAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJmIwU9rNv376Cy/zoRz8quMzatWsLLnPGGWcUXGbWrFkFl4HDRQ8IgCQEEADdP4AaGhrC+eefH/r27RsGDhwYJkyYcMCphF27doXp06eH/v37h+OOOy5MnDgxbN26tbPrDUApBdDSpUvzcFmxYkV4+eWXw549e8K4cePCzp0729a5/fbbw4svvhiee+65fP0PPvggXHfddV1RdwBKZRDCwoUL2z1vbGzMe0KrVq0Kl112WWhubg6PP/54eOqpp8IPfvCDfJ158+blF09jaF144YWdW3sASvMaUAycqKqqKn+MQRR7RWPHjm1b5/TTTw9Dhw4Ny5cvP+jv2L17d2hpaWm3AFD8eh3KcNWZM2eGiy++OJx11ln5a01NTaF3796hX79+7dYdNGhQ/t5XXVeqrKxsW2praztaJQBKIYDitaC33347PPPMM4dUgfr6+rwn1bps3rz5kH4fAEV8I+qMGTPCSy+9FJYtWxaGDBnS9np1dXX4/PPPw7Zt29r1guIouPjewZSXl+cLAKWloB5QlmV5+MyfPz8sXrw4DB8+vN375513XjjqqKPCokWL2l6Lw7Q3bdoURo8e3Xm1BqC0ekDxtFsc4bZgwYL8XqDW6zrx2k2fPn3yx1tuuSXU1dXlAxMqKirCbbfdloePEXAAdDiA5s6dmz9efvnl7V6PQ60nT56c//y73/0u9OrVK78BNY5wGz9+fPjDH/5QyGYAKAFlWTyv1o3EYdixJxUHJMQeFBxOH3/8ccFl4r1wh8PKlSsLLnPuued2SV2gM47j5oIDIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIAB6zjeiQncXZ+HtiMP1vVV//vOfCy7z3e9+t0vqAqnoAQGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAGQhAACIAkBBEASAgiAJExGSlGaN29eh8q9++674XC45JJLCi5TVlbWJXWBVPSAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAGQhAACIAkBBEASJiOl21u3bl3BZe6///4uqQvQefSAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAGQhAACIAkBBEASJiOl23vttdcKLtPS0hIOlzPOOKPgMn369OmSukBPogcEQBICCIDuH0ANDQ3h/PPPD3379g0DBw4MEyZMCGvXrm23zuWXXx7KysraLbfeemtn1xuAUgqgpUuXhunTp4cVK1aEl19+OezZsyeMGzcu7Ny5s916U6ZMCVu2bGlbHnzwwc6uNwClNAhh4cKF7Z43NjbmPaFVq1aFyy67rO31Y445JlRXV3deLQEoOod0Dai5uTl/rKqqavf6k08+GQYMGBDOOuusUF9fHz799NOv/B27d+/ORyztvwBQ/Do8DHvfvn1h5syZ4eKLL86DptVNN90Uhg0bFmpqasKaNWvCXXfdlV8nev7557/yutKsWbM6Wg0ASi2A4rWgt99+O7z++uvtXp86dWrbz2effXYYPHhwGDNmTNiwYUM46aSTDvg9sYdUV1fX9jz2gGpraztaLQCKOYBmzJgRXnrppbBs2bIwZMiQr1131KhR+eP69esPGkDl5eX5AkBpKSiAsiwLt912W5g/f35YsmRJGD58+DeWWb16df4Ye0IA0KEAiqfdnnrqqbBgwYL8XqCmpqb89crKynxqkXiaLb7/wx/+MPTv3z+/BnT77bfnI+TOOeecQjYFQJErKIDmzp3bdrPp/ubNmxcmT54cevfuHV555ZUwe/bs/N6geC1n4sSJ4e677+7cWgNQeqfgvk4MnHizKgB8E7Nhw34uuuiigsvEWUEKZTZsMBkpAIkIIACSEEAAJCGAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEiiLPumKa4Ps/iV3PH7hZqbm0NFRUXq6gDQRcdxPSAAkhBAACQhgABIQgABkIQAAiAJAQRAEgIIgCQEEABJCCAAkhBAACQhgABI4sjQzbROTRfnEgKg52k9fn/TVKPdLoC2b9+eP9bW1qauCgCHeDyPk5L2mNmw9+3bFz744IPQt2/fUFZWdkCqxmDavHlzSc+UbT98wX74gv3wBfuh++yHGCsxfGpqakKvXr16Tg8oVnbIkCFfu07cqaXcwFrZD1+wH75gP3zBfuge++Hrej6tDEIAIAkBBEASPSqAysvLw3333Zc/ljL74Qv2wxfshy/YDz1vP3S7QQgAlIYe1QMCoHgIIACSEEAAJCGAAEiixwTQnDlzwoknnhiOPvroMGrUqPDmm2+GUnP//ffns0Psv5x++umh2C1btixcffXV+V3V8d/8wgsvtHs/jqO59957w+DBg0OfPn3C2LFjw7p160Kp7YfJkycf0D6uvPLKUEwaGhrC+eefn8+UMnDgwDBhwoSwdu3aduvs2rUrTJ8+PfTv3z8cd9xxYeLEiWHr1q2h1PbD5ZdffkB7uPXWW0N30iMC6Nlnnw11dXX50MK33norjBw5MowfPz58+OGHodSceeaZYcuWLW3L66+/Hordzp078//z+CHkYB588MHwyCOPhMceeyy88cYb4dhjj83bRzwQldJ+iGLg7N8+nn766VBMli5dmofLihUrwssvvxz27NkTxo0bl++bVrfffnt48cUXw3PPPZevH6f2uu6660Kp7YdoypQp7dpD/FvpVrIe4IILLsimT5/e9nzv3r1ZTU1N1tDQkJWS++67Lxs5cmRWymKTnT9/ftvzffv2ZdXV1dlDDz3U9tq2bduy8vLy7Omnn85KZT9EkyZNyq655pqslHz44Yf5vli6dGnb//1RRx2VPffcc23r/Otf/8rXWb58eVYq+yH6/ve/n/3sZz/LurNu3wP6/PPPw6pVq/LTKvvPFxefL1++PJSaeGopnoIZMWJEuPnmm8OmTZtCKdu4cWNoampq1z7iHFTxNG0pto8lS5bkp2ROO+20MG3atPDJJ5+EYtbc3Jw/VlVV5Y/xWBF7A/u3h3iaeujQoUXdHpq/tB9aPfnkk2HAgAHhrLPOCvX19eHTTz8N3Um3m4z0yz7++OOwd+/eMGjQoHavx+f//ve/QymJB9XGxsb84BK707NmzQqXXnppePvtt/NzwaUohk90sPbR+l6piKff4qmm4cOHhw0bNoRf/vKX4aqrrsoPvEcccUQoNnHm/JkzZ4aLL744P8BG8f+8d+/eoV+/fiXTHvYdZD9EN910Uxg2bFj+gXXNmjXhrrvuyq8TPf/886G76PYBxP/Eg0mrc845Jw+k2MD+8pe/hFtuuSVp3UjvhhtuaPv57LPPztvISSedlPeKxowZE4pNvAYSP3yVwnXQjuyHqVOntmsPcZBObAfxw0lsF91Btz8FF7uP8dPbl0exxOfV1dWhlMVPeaeeempYv359KFWtbUD7OFA8TRv/foqxfcyYMSO89NJL4dVXX2339S3x/zyett+2bVtJtIcZX7EfDiZ+YI26U3vo9gEUu9PnnXdeWLRoUbsuZ3w+evToUMp27NiRf5qJn2xKVTzdFA8s+7eP+IVccTRcqbeP999/P78GVEztI46/iAfd+fPnh8WLF+f///uLx4qjjjqqXXuIp53itdJiag/ZN+yHg1m9enX+2K3aQ9YDPPPMM/mopsbGxuyf//xnNnXq1Kxfv35ZU1NTVkp+/vOfZ0uWLMk2btyY/e1vf8vGjh2bDRgwIB8BU8y2b9+e/eMf/8iX2GQffvjh/Of//Oc/+fu/+c1v8vawYMGCbM2aNflIsOHDh2efffZZVir7Ib53xx135CO9Yvt45ZVXsnPPPTc75ZRTsl27dmXFYtq0aVllZWX+d7Bly5a25dNPP21b59Zbb82GDh2aLV68OFu5cmU2evTofCkm075hP6xfvz574IEH8n9/bA/xb2PEiBHZZZddlnUnPSKAokcffTRvVL17986HZa9YsSIrNddff302ePDgfB+ccMIJ+fPY0Irdq6++mh9wv7zEYcetQ7HvueeebNCgQfkHlTFjxmRr167NSmk/xAPPuHHjsuOPPz4fhjxs2LBsypQpRfch7WD//rjMmzevbZ34weOnP/1p9q1vfSs75phjsmuvvTY/OJfSfti0aVMeNlVVVfnfxMknn5z94he/yJqbm7PuxNcxAJBEt78GBEBxEkAAJCGAAEhCAAGQhAACIAkBBEASAgiAJAQQAEkIIACSEEAAJCGAAEhCAAEQUvgvxOCdN2HOa/4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_valid[0], cmap='Greys') #cmap parameter makes the pixels black/white like how they are in training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd260d4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
       "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
       "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
       "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
       "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
       "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
       "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
       "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
       "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0] #should get a 28x28 2D array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7a62d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a866c596",
   "metadata": {},
   "source": [
    "### Preprocessing the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ecb1768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change all values in the training set from 8 bit unsigned integers to 32 bit float\n",
    "X_train = X_train.reshape(60000, 784).astype('float32') \n",
    "X_valid = X_valid.reshape(10000,784).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e91af25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We just converted the integers to floats so that we can normalize the values as a float between 0 and 1 \n",
    "# 0 is false, 1 is true, easier for classification \n",
    "X_train /= 255\n",
    "X_valid /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3581c98e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
       "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
       "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
       "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
       "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
       "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
       "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
       "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
       "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
       "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
       "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
       "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
       "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
       "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
       "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
       "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
       "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
       "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid[0] #should see the normalized values (all values in the 2D array are now between 0/1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4d08ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_digits = 10 # the number of possible digits (0-9)\n",
    "\n",
    "# Convert the integer label into a one-hot encoding\n",
    "y_train = to_categorical(y_train, num_digits)\n",
    "y_valid = to_categorical(y_valid, num_digits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5237fa99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid[0] #7 is now encoded by an array of size 10, where all elements are 0 expect for index 7, which is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e595663",
   "metadata": {},
   "source": [
    "We do this one-hot encoding because it is the optimal output of the neural network when it is fed with 7 (or whatever input we give it). We can interpret this output format as having a 1 (100%) chance that the input digit is a 7, while all other digits have a probability of 0. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b771c7e",
   "metadata": {},
   "source": [
    "#### Design Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d928da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "#input layer:\n",
    "model.add(Input(shape=(784,)))\n",
    "model.add(Dense(64, activation='sigmoid')) #64 sigmoid neurons \n",
    "\n",
    "#input_shape specifies how many inputs the model should expect (784 for the 28x28 size input digits)\n",
    "\n",
    "#output layer:\n",
    "model.add(Dense(10, activation='softmax')) #10 softmax neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "060940f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m50,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m650\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82bc23c",
   "metadata": {},
   "source": [
    "# Explanation of the numbers from model.summary():\n",
    "\n",
    "<b>Total # of parameters in a layer = total # of weights + total # of biases</b>\n",
    "\n",
    "(784 inputs/neuron * 64 neurons in hidden layer) + 64*(1 bias/neuron) = <b>50240 parameters</b> for first dense layer\n",
    "\n",
    "\n",
    "(64 inputs/neuron * 10 neurons in dense_1 layer) + 10*(1 bias/neuron) = <b>650 parameters</b> for second dense layer\n",
    "\n",
    "\n",
    "Therefore, the total parameters = sum of all parameters in all layers = <b>50890 parameters</b>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033c2633",
   "metadata": {},
   "source": [
    "#### Compiling the model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38f0ef68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss: measures where our model is incorrect (a metric to measure how much error in approximation)\n",
    "# SGD: stocastic gradient descent\n",
    "# lr: learning rate\n",
    "# accuracy: % of correct guesses that model makes\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01), metrics=['accuracy'])\n",
    "              \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd8e241",
   "metadata": {},
   "source": [
    "#### Training the model (post-compilation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5183bc7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 763us/step - accuracy: 0.1365 - loss: 0.0936 - val_accuracy: 0.1431 - val_loss: 0.0922\n",
      "Epoch 2/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 632us/step - accuracy: 0.1478 - loss: 0.0919 - val_accuracy: 0.1511 - val_loss: 0.0911\n",
      "Epoch 3/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 638us/step - accuracy: 0.1525 - loss: 0.0910 - val_accuracy: 0.1562 - val_loss: 0.0905\n",
      "Epoch 4/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 616us/step - accuracy: 0.1605 - loss: 0.0904 - val_accuracy: 0.1662 - val_loss: 0.0900\n",
      "Epoch 5/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 627us/step - accuracy: 0.1671 - loss: 0.0899 - val_accuracy: 0.1795 - val_loss: 0.0896\n",
      "Epoch 6/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 628us/step - accuracy: 0.1835 - loss: 0.0895 - val_accuracy: 0.1994 - val_loss: 0.0893\n",
      "Epoch 7/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.2024 - loss: 0.0892 - val_accuracy: 0.2342 - val_loss: 0.0889\n",
      "Epoch 8/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 639us/step - accuracy: 0.2347 - loss: 0.0888 - val_accuracy: 0.2627 - val_loss: 0.0886\n",
      "Epoch 9/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.2619 - loss: 0.0885 - val_accuracy: 0.2865 - val_loss: 0.0883\n",
      "Epoch 10/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.2827 - loss: 0.0882 - val_accuracy: 0.3077 - val_loss: 0.0880\n",
      "Epoch 11/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.3017 - loss: 0.0879 - val_accuracy: 0.3207 - val_loss: 0.0876\n",
      "Epoch 12/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.3138 - loss: 0.0876 - val_accuracy: 0.3316 - val_loss: 0.0873\n",
      "Epoch 13/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.3262 - loss: 0.0873 - val_accuracy: 0.3395 - val_loss: 0.0870\n",
      "Epoch 14/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.3383 - loss: 0.0869 - val_accuracy: 0.3507 - val_loss: 0.0867\n",
      "Epoch 15/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.3515 - loss: 0.0866 - val_accuracy: 0.3673 - val_loss: 0.0863\n",
      "Epoch 16/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 629us/step - accuracy: 0.3727 - loss: 0.0863 - val_accuracy: 0.3910 - val_loss: 0.0860\n",
      "Epoch 17/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.3907 - loss: 0.0860 - val_accuracy: 0.4078 - val_loss: 0.0857\n",
      "Epoch 18/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.4073 - loss: 0.0856 - val_accuracy: 0.4210 - val_loss: 0.0853\n",
      "Epoch 19/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.4235 - loss: 0.0853 - val_accuracy: 0.4323 - val_loss: 0.0850\n",
      "Epoch 20/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.4351 - loss: 0.0849 - val_accuracy: 0.4421 - val_loss: 0.0846\n",
      "Epoch 21/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 641us/step - accuracy: 0.4429 - loss: 0.0846 - val_accuracy: 0.4490 - val_loss: 0.0843\n",
      "Epoch 22/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.4475 - loss: 0.0843 - val_accuracy: 0.4559 - val_loss: 0.0839\n",
      "Epoch 23/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.4518 - loss: 0.0839 - val_accuracy: 0.4570 - val_loss: 0.0835\n",
      "Epoch 24/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.4508 - loss: 0.0835 - val_accuracy: 0.4612 - val_loss: 0.0831\n",
      "Epoch 25/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.4584 - loss: 0.0831 - val_accuracy: 0.4624 - val_loss: 0.0827\n",
      "Epoch 26/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 636us/step - accuracy: 0.4588 - loss: 0.0827 - val_accuracy: 0.4642 - val_loss: 0.0823\n",
      "Epoch 27/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.4569 - loss: 0.0823 - val_accuracy: 0.4658 - val_loss: 0.0819\n",
      "Epoch 28/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.4640 - loss: 0.0818 - val_accuracy: 0.4682 - val_loss: 0.0814\n",
      "Epoch 29/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 683us/step - accuracy: 0.4637 - loss: 0.0814 - val_accuracy: 0.4684 - val_loss: 0.0810\n",
      "Epoch 30/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.4651 - loss: 0.0810 - val_accuracy: 0.4704 - val_loss: 0.0805\n",
      "Epoch 31/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.4697 - loss: 0.0804 - val_accuracy: 0.4725 - val_loss: 0.0801\n",
      "Epoch 32/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.4723 - loss: 0.0801 - val_accuracy: 0.4748 - val_loss: 0.0796\n",
      "Epoch 33/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.4739 - loss: 0.0796 - val_accuracy: 0.4774 - val_loss: 0.0791\n",
      "Epoch 34/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.4761 - loss: 0.0791 - val_accuracy: 0.4805 - val_loss: 0.0787\n",
      "Epoch 35/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.4822 - loss: 0.0786 - val_accuracy: 0.4844 - val_loss: 0.0782\n",
      "Epoch 36/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.4843 - loss: 0.0781 - val_accuracy: 0.4868 - val_loss: 0.0777\n",
      "Epoch 37/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.4853 - loss: 0.0778 - val_accuracy: 0.4888 - val_loss: 0.0772\n",
      "Epoch 38/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.4923 - loss: 0.0771 - val_accuracy: 0.4923 - val_loss: 0.0767\n",
      "Epoch 39/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.4964 - loss: 0.0767 - val_accuracy: 0.4959 - val_loss: 0.0762\n",
      "Epoch 40/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.4988 - loss: 0.0762 - val_accuracy: 0.4992 - val_loss: 0.0757\n",
      "Epoch 41/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.5001 - loss: 0.0758 - val_accuracy: 0.5025 - val_loss: 0.0751\n",
      "Epoch 42/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.5081 - loss: 0.0752 - val_accuracy: 0.5078 - val_loss: 0.0746\n",
      "Epoch 43/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.5105 - loss: 0.0747 - val_accuracy: 0.5130 - val_loss: 0.0741\n",
      "Epoch 44/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.5205 - loss: 0.0741 - val_accuracy: 0.5175 - val_loss: 0.0736\n",
      "Epoch 45/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.5209 - loss: 0.0737 - val_accuracy: 0.5216 - val_loss: 0.0731\n",
      "Epoch 46/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.5267 - loss: 0.0732 - val_accuracy: 0.5264 - val_loss: 0.0725\n",
      "Epoch 47/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.5316 - loss: 0.0726 - val_accuracy: 0.5311 - val_loss: 0.0720\n",
      "Epoch 48/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.5356 - loss: 0.0722 - val_accuracy: 0.5362 - val_loss: 0.0715\n",
      "Epoch 49/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.5408 - loss: 0.0716 - val_accuracy: 0.5431 - val_loss: 0.0710\n",
      "Epoch 50/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.5454 - loss: 0.0712 - val_accuracy: 0.5468 - val_loss: 0.0704\n",
      "Epoch 51/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.5492 - loss: 0.0706 - val_accuracy: 0.5517 - val_loss: 0.0699\n",
      "Epoch 52/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.5575 - loss: 0.0700 - val_accuracy: 0.5564 - val_loss: 0.0694\n",
      "Epoch 53/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.5613 - loss: 0.0696 - val_accuracy: 0.5608 - val_loss: 0.0689\n",
      "Epoch 54/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.5677 - loss: 0.0690 - val_accuracy: 0.5646 - val_loss: 0.0683\n",
      "Epoch 55/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.5737 - loss: 0.0683 - val_accuracy: 0.5689 - val_loss: 0.0678\n",
      "Epoch 56/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.5762 - loss: 0.0679 - val_accuracy: 0.5748 - val_loss: 0.0673\n",
      "Epoch 57/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.5830 - loss: 0.0673 - val_accuracy: 0.5799 - val_loss: 0.0668\n",
      "Epoch 58/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.5819 - loss: 0.0671 - val_accuracy: 0.5840 - val_loss: 0.0663\n",
      "Epoch 59/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.5873 - loss: 0.0664 - val_accuracy: 0.5880 - val_loss: 0.0657\n",
      "Epoch 60/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.5922 - loss: 0.0660 - val_accuracy: 0.5920 - val_loss: 0.0652\n",
      "Epoch 61/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.5952 - loss: 0.0653 - val_accuracy: 0.5970 - val_loss: 0.0647\n",
      "Epoch 62/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.5966 - loss: 0.0650 - val_accuracy: 0.6003 - val_loss: 0.0642\n",
      "Epoch 63/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.6032 - loss: 0.0644 - val_accuracy: 0.6036 - val_loss: 0.0637\n",
      "Epoch 64/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.6028 - loss: 0.0641 - val_accuracy: 0.6070 - val_loss: 0.0632\n",
      "Epoch 65/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.6049 - loss: 0.0636 - val_accuracy: 0.6100 - val_loss: 0.0627\n",
      "Epoch 66/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.6052 - loss: 0.0633 - val_accuracy: 0.6128 - val_loss: 0.0622\n",
      "Epoch 67/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.6117 - loss: 0.0626 - val_accuracy: 0.6159 - val_loss: 0.0618\n",
      "Epoch 68/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.6168 - loss: 0.0621 - val_accuracy: 0.6178 - val_loss: 0.0613\n",
      "Epoch 69/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.6165 - loss: 0.0616 - val_accuracy: 0.6209 - val_loss: 0.0608\n",
      "Epoch 70/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.6167 - loss: 0.0612 - val_accuracy: 0.6230 - val_loss: 0.0603\n",
      "Epoch 71/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.6210 - loss: 0.0608 - val_accuracy: 0.6253 - val_loss: 0.0599\n",
      "Epoch 72/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.6252 - loss: 0.0601 - val_accuracy: 0.6271 - val_loss: 0.0594\n",
      "Epoch 73/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.6243 - loss: 0.0597 - val_accuracy: 0.6293 - val_loss: 0.0590\n",
      "Epoch 74/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.6266 - loss: 0.0594 - val_accuracy: 0.6322 - val_loss: 0.0585\n",
      "Epoch 75/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.6329 - loss: 0.0587 - val_accuracy: 0.6347 - val_loss: 0.0581\n",
      "Epoch 76/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.6298 - loss: 0.0585 - val_accuracy: 0.6371 - val_loss: 0.0576\n",
      "Epoch 77/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.6318 - loss: 0.0581 - val_accuracy: 0.6404 - val_loss: 0.0572\n",
      "Epoch 78/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.6347 - loss: 0.0577 - val_accuracy: 0.6433 - val_loss: 0.0567\n",
      "Epoch 79/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 643us/step - accuracy: 0.6391 - loss: 0.0570 - val_accuracy: 0.6455 - val_loss: 0.0563\n",
      "Epoch 80/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.6403 - loss: 0.0568 - val_accuracy: 0.6488 - val_loss: 0.0559\n",
      "Epoch 81/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.6468 - loss: 0.0562 - val_accuracy: 0.6524 - val_loss: 0.0555\n",
      "Epoch 82/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.6451 - loss: 0.0559 - val_accuracy: 0.6552 - val_loss: 0.0551\n",
      "Epoch 83/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.6488 - loss: 0.0554 - val_accuracy: 0.6585 - val_loss: 0.0547\n",
      "Epoch 84/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.6526 - loss: 0.0550 - val_accuracy: 0.6619 - val_loss: 0.0543\n",
      "Epoch 85/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.6532 - loss: 0.0548 - val_accuracy: 0.6658 - val_loss: 0.0539\n",
      "Epoch 86/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.6600 - loss: 0.0541 - val_accuracy: 0.6690 - val_loss: 0.0535\n",
      "Epoch 87/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.6580 - loss: 0.0543 - val_accuracy: 0.6723 - val_loss: 0.0531\n",
      "Epoch 88/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.6634 - loss: 0.0536 - val_accuracy: 0.6752 - val_loss: 0.0527\n",
      "Epoch 89/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.6677 - loss: 0.0532 - val_accuracy: 0.6785 - val_loss: 0.0523\n",
      "Epoch 90/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.6697 - loss: 0.0530 - val_accuracy: 0.6818 - val_loss: 0.0520\n",
      "Epoch 91/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.6742 - loss: 0.0525 - val_accuracy: 0.6852 - val_loss: 0.0516\n",
      "Epoch 92/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.6788 - loss: 0.0521 - val_accuracy: 0.6900 - val_loss: 0.0512\n",
      "Epoch 93/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.6799 - loss: 0.0518 - val_accuracy: 0.6937 - val_loss: 0.0509\n",
      "Epoch 94/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 673us/step - accuracy: 0.6845 - loss: 0.0514 - val_accuracy: 0.6973 - val_loss: 0.0505\n",
      "Epoch 95/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.6822 - loss: 0.0513 - val_accuracy: 0.7008 - val_loss: 0.0502\n",
      "Epoch 96/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.6925 - loss: 0.0505 - val_accuracy: 0.7033 - val_loss: 0.0498\n",
      "Epoch 97/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 669us/step - accuracy: 0.6912 - loss: 0.0505 - val_accuracy: 0.7071 - val_loss: 0.0495\n",
      "Epoch 98/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.6935 - loss: 0.0503 - val_accuracy: 0.7109 - val_loss: 0.0491\n",
      "Epoch 99/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7012 - loss: 0.0495 - val_accuracy: 0.7145 - val_loss: 0.0488\n",
      "Epoch 100/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7037 - loss: 0.0494 - val_accuracy: 0.7169 - val_loss: 0.0485\n",
      "Epoch 101/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.7065 - loss: 0.0491 - val_accuracy: 0.7207 - val_loss: 0.0481\n",
      "Epoch 102/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7086 - loss: 0.0487 - val_accuracy: 0.7249 - val_loss: 0.0478\n",
      "Epoch 103/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7110 - loss: 0.0483 - val_accuracy: 0.7278 - val_loss: 0.0475\n",
      "Epoch 104/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7151 - loss: 0.0480 - val_accuracy: 0.7304 - val_loss: 0.0472\n",
      "Epoch 105/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7157 - loss: 0.0480 - val_accuracy: 0.7329 - val_loss: 0.0469\n",
      "Epoch 106/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7170 - loss: 0.0476 - val_accuracy: 0.7353 - val_loss: 0.0465\n",
      "Epoch 107/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7221 - loss: 0.0474 - val_accuracy: 0.7376 - val_loss: 0.0462\n",
      "Epoch 108/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.7245 - loss: 0.0469 - val_accuracy: 0.7402 - val_loss: 0.0459\n",
      "Epoch 109/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7283 - loss: 0.0466 - val_accuracy: 0.7428 - val_loss: 0.0456\n",
      "Epoch 110/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7312 - loss: 0.0463 - val_accuracy: 0.7455 - val_loss: 0.0453\n",
      "Epoch 111/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.7356 - loss: 0.0459 - val_accuracy: 0.7482 - val_loss: 0.0450\n",
      "Epoch 112/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7380 - loss: 0.0457 - val_accuracy: 0.7506 - val_loss: 0.0447\n",
      "Epoch 113/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7361 - loss: 0.0456 - val_accuracy: 0.7534 - val_loss: 0.0445\n",
      "Epoch 114/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7400 - loss: 0.0452 - val_accuracy: 0.7552 - val_loss: 0.0442\n",
      "Epoch 115/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.7414 - loss: 0.0449 - val_accuracy: 0.7576 - val_loss: 0.0439\n",
      "Epoch 116/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7447 - loss: 0.0446 - val_accuracy: 0.7592 - val_loss: 0.0436\n",
      "Epoch 117/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.7483 - loss: 0.0443 - val_accuracy: 0.7604 - val_loss: 0.0433\n",
      "Epoch 118/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7456 - loss: 0.0441 - val_accuracy: 0.7619 - val_loss: 0.0431\n",
      "Epoch 119/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.7520 - loss: 0.0436 - val_accuracy: 0.7645 - val_loss: 0.0428\n",
      "Epoch 120/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.7524 - loss: 0.0436 - val_accuracy: 0.7672 - val_loss: 0.0425\n",
      "Epoch 121/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.7555 - loss: 0.0433 - val_accuracy: 0.7697 - val_loss: 0.0422\n",
      "Epoch 122/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7593 - loss: 0.0429 - val_accuracy: 0.7711 - val_loss: 0.0420\n",
      "Epoch 123/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 652us/step - accuracy: 0.7606 - loss: 0.0426 - val_accuracy: 0.7732 - val_loss: 0.0417\n",
      "Epoch 124/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7591 - loss: 0.0426 - val_accuracy: 0.7751 - val_loss: 0.0415\n",
      "Epoch 125/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.7648 - loss: 0.0421 - val_accuracy: 0.7766 - val_loss: 0.0412\n",
      "Epoch 126/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7688 - loss: 0.0418 - val_accuracy: 0.7786 - val_loss: 0.0410\n",
      "Epoch 127/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7729 - loss: 0.0413 - val_accuracy: 0.7807 - val_loss: 0.0407\n",
      "Epoch 128/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.7717 - loss: 0.0413 - val_accuracy: 0.7824 - val_loss: 0.0404\n",
      "Epoch 129/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 661us/step - accuracy: 0.7711 - loss: 0.0414 - val_accuracy: 0.7843 - val_loss: 0.0402\n",
      "Epoch 130/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.7749 - loss: 0.0410 - val_accuracy: 0.7863 - val_loss: 0.0400\n",
      "Epoch 131/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.7783 - loss: 0.0406 - val_accuracy: 0.7870 - val_loss: 0.0397\n",
      "Epoch 132/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.7786 - loss: 0.0405 - val_accuracy: 0.7890 - val_loss: 0.0395\n",
      "Epoch 133/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.7823 - loss: 0.0401 - val_accuracy: 0.7904 - val_loss: 0.0392\n",
      "Epoch 134/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.7814 - loss: 0.0400 - val_accuracy: 0.7933 - val_loss: 0.0390\n",
      "Epoch 135/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.7856 - loss: 0.0398 - val_accuracy: 0.7952 - val_loss: 0.0388\n",
      "Epoch 136/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.7885 - loss: 0.0394 - val_accuracy: 0.7968 - val_loss: 0.0385\n",
      "Epoch 137/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.7861 - loss: 0.0395 - val_accuracy: 0.7991 - val_loss: 0.0383\n",
      "Epoch 138/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.7918 - loss: 0.0391 - val_accuracy: 0.8007 - val_loss: 0.0381\n",
      "Epoch 139/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 686us/step - accuracy: 0.7945 - loss: 0.0387 - val_accuracy: 0.8023 - val_loss: 0.0379\n",
      "Epoch 140/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.7969 - loss: 0.0385 - val_accuracy: 0.8041 - val_loss: 0.0376\n",
      "Epoch 141/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.7959 - loss: 0.0384 - val_accuracy: 0.8062 - val_loss: 0.0374\n",
      "Epoch 142/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.7990 - loss: 0.0381 - val_accuracy: 0.8082 - val_loss: 0.0372\n",
      "Epoch 143/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.8033 - loss: 0.0379 - val_accuracy: 0.8096 - val_loss: 0.0370\n",
      "Epoch 144/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8016 - loss: 0.0379 - val_accuracy: 0.8116 - val_loss: 0.0368\n",
      "Epoch 145/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.8037 - loss: 0.0376 - val_accuracy: 0.8125 - val_loss: 0.0366\n",
      "Epoch 146/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8046 - loss: 0.0374 - val_accuracy: 0.8148 - val_loss: 0.0364\n",
      "Epoch 147/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8101 - loss: 0.0370 - val_accuracy: 0.8166 - val_loss: 0.0362\n",
      "Epoch 148/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.8116 - loss: 0.0368 - val_accuracy: 0.8179 - val_loss: 0.0359\n",
      "Epoch 149/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8106 - loss: 0.0368 - val_accuracy: 0.8193 - val_loss: 0.0357\n",
      "Epoch 150/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8131 - loss: 0.0365 - val_accuracy: 0.8205 - val_loss: 0.0355\n",
      "Epoch 151/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8129 - loss: 0.0365 - val_accuracy: 0.8225 - val_loss: 0.0353\n",
      "Epoch 152/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8137 - loss: 0.0363 - val_accuracy: 0.8246 - val_loss: 0.0352\n",
      "Epoch 153/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8178 - loss: 0.0359 - val_accuracy: 0.8256 - val_loss: 0.0350\n",
      "Epoch 154/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.8180 - loss: 0.0357 - val_accuracy: 0.8271 - val_loss: 0.0348\n",
      "Epoch 155/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8177 - loss: 0.0356 - val_accuracy: 0.8281 - val_loss: 0.0346\n",
      "Epoch 156/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8193 - loss: 0.0356 - val_accuracy: 0.8304 - val_loss: 0.0344\n",
      "Epoch 157/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8238 - loss: 0.0352 - val_accuracy: 0.8327 - val_loss: 0.0342\n",
      "Epoch 158/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.8257 - loss: 0.0349 - val_accuracy: 0.8335 - val_loss: 0.0340\n",
      "Epoch 159/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8246 - loss: 0.0349 - val_accuracy: 0.8346 - val_loss: 0.0338\n",
      "Epoch 160/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8262 - loss: 0.0345 - val_accuracy: 0.8357 - val_loss: 0.0336\n",
      "Epoch 161/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.8288 - loss: 0.0343 - val_accuracy: 0.8367 - val_loss: 0.0335\n",
      "Epoch 162/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8275 - loss: 0.0344 - val_accuracy: 0.8387 - val_loss: 0.0333\n",
      "Epoch 163/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8315 - loss: 0.0341 - val_accuracy: 0.8399 - val_loss: 0.0331\n",
      "Epoch 164/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8297 - loss: 0.0341 - val_accuracy: 0.8409 - val_loss: 0.0329\n",
      "Epoch 165/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 663us/step - accuracy: 0.8328 - loss: 0.0337 - val_accuracy: 0.8425 - val_loss: 0.0328\n",
      "Epoch 166/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8316 - loss: 0.0338 - val_accuracy: 0.8431 - val_loss: 0.0326\n",
      "Epoch 167/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 668us/step - accuracy: 0.8348 - loss: 0.0334 - val_accuracy: 0.8440 - val_loss: 0.0324\n",
      "Epoch 168/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.8340 - loss: 0.0333 - val_accuracy: 0.8445 - val_loss: 0.0323\n",
      "Epoch 169/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 649us/step - accuracy: 0.8360 - loss: 0.0332 - val_accuracy: 0.8455 - val_loss: 0.0321\n",
      "Epoch 170/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8377 - loss: 0.0329 - val_accuracy: 0.8465 - val_loss: 0.0319\n",
      "Epoch 171/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.8406 - loss: 0.0327 - val_accuracy: 0.8473 - val_loss: 0.0318\n",
      "Epoch 172/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.8389 - loss: 0.0326 - val_accuracy: 0.8485 - val_loss: 0.0316\n",
      "Epoch 173/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.8396 - loss: 0.0324 - val_accuracy: 0.8490 - val_loss: 0.0315\n",
      "Epoch 174/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 664us/step - accuracy: 0.8420 - loss: 0.0322 - val_accuracy: 0.8500 - val_loss: 0.0313\n",
      "Epoch 175/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8415 - loss: 0.0321 - val_accuracy: 0.8510 - val_loss: 0.0312\n",
      "Epoch 176/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.8433 - loss: 0.0319 - val_accuracy: 0.8512 - val_loss: 0.0310\n",
      "Epoch 177/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - accuracy: 0.8437 - loss: 0.0318 - val_accuracy: 0.8516 - val_loss: 0.0309\n",
      "Epoch 178/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 653us/step - accuracy: 0.8433 - loss: 0.0317 - val_accuracy: 0.8523 - val_loss: 0.0307\n",
      "Epoch 179/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.8427 - loss: 0.0317 - val_accuracy: 0.8527 - val_loss: 0.0306\n",
      "Epoch 180/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8449 - loss: 0.0313 - val_accuracy: 0.8532 - val_loss: 0.0304\n",
      "Epoch 181/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8453 - loss: 0.0314 - val_accuracy: 0.8538 - val_loss: 0.0303\n",
      "Epoch 182/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 646us/step - accuracy: 0.8485 - loss: 0.0309 - val_accuracy: 0.8542 - val_loss: 0.0301\n",
      "Epoch 183/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8471 - loss: 0.0310 - val_accuracy: 0.8550 - val_loss: 0.0300\n",
      "Epoch 184/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 648us/step - accuracy: 0.8482 - loss: 0.0306 - val_accuracy: 0.8559 - val_loss: 0.0298\n",
      "Epoch 185/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8485 - loss: 0.0307 - val_accuracy: 0.8565 - val_loss: 0.0297\n",
      "Epoch 186/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.8488 - loss: 0.0306 - val_accuracy: 0.8571 - val_loss: 0.0296\n",
      "Epoch 187/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 672us/step - accuracy: 0.8510 - loss: 0.0303 - val_accuracy: 0.8580 - val_loss: 0.0294\n",
      "Epoch 188/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 659us/step - accuracy: 0.8519 - loss: 0.0302 - val_accuracy: 0.8579 - val_loss: 0.0293\n",
      "Epoch 189/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.8529 - loss: 0.0300 - val_accuracy: 0.8587 - val_loss: 0.0292\n",
      "Epoch 190/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 699us/step - accuracy: 0.8499 - loss: 0.0301 - val_accuracy: 0.8594 - val_loss: 0.0290\n",
      "Epoch 191/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.8506 - loss: 0.0300 - val_accuracy: 0.8602 - val_loss: 0.0289\n",
      "Epoch 192/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.8544 - loss: 0.0297 - val_accuracy: 0.8608 - val_loss: 0.0288\n",
      "Epoch 193/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.8484 - loss: 0.0300 - val_accuracy: 0.8612 - val_loss: 0.0287\n",
      "Epoch 194/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8530 - loss: 0.0296 - val_accuracy: 0.8617 - val_loss: 0.0285\n",
      "Epoch 195/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - accuracy: 0.8542 - loss: 0.0295 - val_accuracy: 0.8618 - val_loss: 0.0284\n",
      "Epoch 196/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 650us/step - accuracy: 0.8548 - loss: 0.0291 - val_accuracy: 0.8621 - val_loss: 0.0283\n",
      "Epoch 197/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.8544 - loss: 0.0293 - val_accuracy: 0.8619 - val_loss: 0.0282\n",
      "Epoch 198/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 656us/step - accuracy: 0.8578 - loss: 0.0288 - val_accuracy: 0.8622 - val_loss: 0.0281\n",
      "Epoch 199/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 644us/step - accuracy: 0.8575 - loss: 0.0289 - val_accuracy: 0.8627 - val_loss: 0.0279\n",
      "Epoch 200/200\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 657us/step - accuracy: 0.8531 - loss: 0.0290 - val_accuracy: 0.8628 - val_loss: 0.0278\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1641f78e0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid)) \n",
    "# verbose=1 will produce outputs as model trains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd660a9",
   "metadata": {},
   "source": [
    "#### Evaluate the models overall performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f973c079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 539us/step - accuracy: 0.8411 - loss: 0.0308\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.027823923155665398, 0.8628000020980835]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a2686",
   "metadata": {},
   "source": [
    "With a simple shallow architecture, still able to accurately predict digit 86% of the time. Increasing the number of epochs will not significantly increase the accuracy of the model as shown with the accuracy trend in the last few steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b76ebc3",
   "metadata": {},
   "source": [
    "#### Perform inference (check what model will predict for a given input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "755014aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_0 = X_valid[0].reshape(1, 784) #just get one input which is 784 (28x28) in size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b9a07a1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.6577826e-03, 7.9463294e-04, 2.3668197e-03, 6.3125002e-03,\n",
       "        6.5576392e-03, 1.4565578e-02, 7.1712059e-04, 9.1214538e-01,\n",
       "        9.0626348e-03, 4.2819839e-02]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(valid_0) #input valid_0 into our shallow neural network "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f2693c",
   "metadata": {},
   "source": [
    "From the output array, 9.2151618e-01 is the highest probability, which corresponds to index 7. Thus, the model will predict that the input digit is a 7. This is expected as X_valid[0] is a 7 from the validation set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b98473c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([7])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.argmax(model.predict(valid_0), axis=-1) #gets the highest probability in the output array"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
